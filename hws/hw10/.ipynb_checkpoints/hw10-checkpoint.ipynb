{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import KeyedVectors, Word2Vec, phrases\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation,strip_numeric,remove_stopwords\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaModel\n",
    "from os import walk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Clean data\n",
    "def text_cleaning(data):\n",
    "    new_sentences = []\n",
    "    filters = [lambda x: x.lower(), strip_tags, strip_punctuation,strip_numeric,remove_stopwords]\n",
    "    no_findings = []\n",
    "    for i in range(data.shape[0]):\n",
    "        txt = data.iloc[i]\n",
    "        c_words = []\n",
    "        words = preprocessing.preprocess_string(txt, filters)\n",
    "        for w in words:\n",
    "            if len(w)>3 :\n",
    "                c_words.append(w)\n",
    "            new_sentences.append(c_words)\n",
    "    \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Breast_Cancer.csv\")['Text']\n",
    "sentences = text_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Breast_Cancer.csv\")['Text']\n",
    "sentences = text_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Bigrams\n",
    "bigram = gensim.models.Phrases(sentences) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "data_ready = [bigram_mod[doc] for doc in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = Word2Vec(workers=8,size=100, iter=10, min_count=1, \n",
    "                        window = 4, negative = 5) # create the model object\n",
    "\n",
    "\n",
    "model_tune = Word2Vec(workers=8,size=100, iter=10, min_count=1, \n",
    "                        window = 4, negative = 5) # create the model object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scratch.build_vocab(data_ready) \n",
    "total_examples = model_scratch.corpus_count\n",
    "total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94560"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tune.build_vocab(data_ready) \n",
    "total_examples = model_tune.corpus_count\n",
    "total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train from scratch\n",
    "model_scratch.train(data_ready, total_examples=total_examples, epochs=200)\n",
    "model_scratch.save(\"w2vec_scratch.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune from drug-related w2vec\n",
    "path_tune = \"dms/trig-vectors-phrase.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
